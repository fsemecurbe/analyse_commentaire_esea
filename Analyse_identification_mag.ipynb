{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4cbb47-c9ba-4faf-b8ed-a69c50fbc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -q -q spacy\n",
    "!pip install -q -q -q more-itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f811f032-22e4-4307-9e07-3d12185ae904",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -q -q unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbd6ecb-18b2-4007-9a87-cfb3461c18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\python.exe: No module named -q\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd139cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import itertools\n",
    "from functools import reduce  \n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357377d7-5882-4f53-bf96-ddb64e56ec72",
   "metadata": {},
   "source": [
    "un peu de NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264064b4-3433-4f36-ad23-828d1f2266a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Une', 'un', 'DET'), ('tendance', 'tendance', 'NOUN'), ('de', 'de', 'ADP'), ('fond', 'fond', 'NOUN'), ('est', 'être', 'AUX'), ('elle', 'lui', 'PRON'), ('en', 'en', 'ADP'), ('train', 'train', 'NOUN'), ('de', 'de', 'ADP'), ('s’', 's’', 'PRON'), ('installer', 'installer', 'VERB'), ('?', '?', 'PUNCT'), ('«', '«', 'PUNCT'), ('La', 'le', 'DET'), ('question', 'question', 'NOUN'), ('se', 'se', 'PRON'), ('pose', 'pose', 'VERB'), ('.', '.', 'PUNCT'), ('Ce', 'ce', 'DET'), ('surrisque', 'surrisqu', 'ADJ'), ('qu’', 'qu’', 'PRON'), ('on', 'on', 'PRON'), ('observe', 'observe', 'VERB'), ('est', 'être', 'AUX'), ('-il', 'il', 'PRON'), ('constant', 'constant', 'ADJ'), ('au', 'au', 'ADP'), ('cours', 'cours', 'NOUN'), ('du', 'de', 'ADP'), ('temps', 'temps', 'NOUN'), (',', ',', 'PUNCT'), ('auquel', 'auquel', 'ADJ'), ('cas', 'cas', 'NOUN'), ('on', 'on', 'PRON'), ('va', 'aller', 'VERB'), ('avoir', 'avoir', 'VERB'), ('une', 'un', 'DET'), ('accumulation', 'accumulation', 'NOUN'), (',', ',', 'PUNCT'), ('ou', 'ou', 'CCONJ'), ('bien', 'bien', 'ADV'), ('est', 'être', 'AUX'), ('-ce', '-ce', 'PRON'), ('que', 'que', 'SCONJ'), ('cet', 'ce', 'DET'), ('effet', 'effet', 'NOUN'), ('va', 'aller', 'VERB'), ('s’', 's’', 'PRON'), ('estomper', 'estomper', 'VERB'), ('au', 'au', 'ADP'), ('fur', 'fur', 'NOUN'), ('et', 'et', 'CCONJ'), ('à', 'à', 'ADP'), ('mesure', 'mesure', 'NOUN'), ('?', '?', 'PUNCT'), ('»', '»', 'PUNCT'), ('s’', 's’', 'PRON'), ('interroge', 'interroger', 'VERB'), ('à', 'à', 'ADP'), ('haute', 'haute', 'DET'), ('voix', 'voix', 'NOUN'), ('l’', 'l’', 'DET'), ('épidémiologiste', 'épidémiologiste', 'NOUN'), ('Mircea', 'Mircea', 'PROPN'), ('Sofonea', 'Sofonea', 'PROPN'), ('.', '.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Une tendance de fond est elle en train de s’installer ? «La question se pose. Ce surrisque qu’on observe est-il constant au cours du temps, auquel cas on va avoir une accumulation, ou bien est-ce que cet effet va s’estomper au fur et à mesure ?» s’interroge à haute voix l’épidémiologiste Mircea Sofonea.')\n",
    "print([(token.text, token.lemma_, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080bbf5",
   "metadata": {},
   "source": [
    "#### Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550750d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274/3177199949.py:1: DtypeWarning: Columns (13,21,28,30,45,49,53,58,65,68,72,74,76,82,84,86,90,97,101,112,116,117,139,149,159,160,166,167,168,169,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  identification = pd.read_csv('data/IDENTIFICATION.csv',sep=';', dtype={'ACCEPT':str,'NOM_DOSSIER':str})\n"
     ]
    }
   ],
   "source": [
    "identification = pd.read_csv('data/IDENTIFICATION.csv',sep=';', dtype={'ACCEPT':str,'NOM_DOSSIER':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431ed02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "identification.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef82e9",
   "metadata": {},
   "source": [
    "#### Traitement du langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96bedaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_a_chercher = ['deceder', 'malade', 'maladie', 'siret', 'siren', 'pacage', 'mort', 'telephone', 'reprise', 'repreneur', 'retraite',\n",
    "                   'cessation', 'cesser', 'arret', 'dcd', 'retraite', 'stopper', 'decede', 'deces', 'exister', 'existe', 'sante', 'retraiter', 'liquidation', 'liquider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a346b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCEPT_COMMENT', 'COMMENT_IDENT', 'PROD_COMMENT', 'AUTRE_COMMENT']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_commentaires = [comment for comment in  identification.columns if \"COMMENT\" in comment]\n",
    "variables_commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "426866fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCEPT_COMMENT\n",
      "Nombre de commentaires : 603\n",
      "COMMENT_IDENT\n",
      "Nombre de commentaires : 4788\n",
      "PROD_COMMENT\n",
      "Nombre de commentaires : 59\n",
      "AUTRE_COMMENT\n",
      "Nombre de commentaires : 489\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for var in variables_commentaires:\n",
    "    df =  identification[~identification[var].isna()][['NOM_DOSSIER', var]].copy()\n",
    "    df[var] = df[var].str.lower()\n",
    "    print(var)\n",
    "    print('Nombre de commentaires :', df.shape[0])\n",
    "    # nlp.pipe permet d'appliquer un réseau de neurone pour lemmatiser le texte\n",
    "    docs = list(nlp.pipe(df[var].values))\n",
    "    tokens = [[unidecode.unidecode(item.lemma_) for item in doc] for doc in docs] \n",
    "    df[var+'_parser'] = list(map(lambda x: np.intersect1d(x,mots_a_chercher), tokens))\n",
    "    df[var+'_parser'] = df[var+'_parser'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # j'utilise des regex pour trouver les numéros de téléphones\n",
    "    telephone = df[~df[var].isna()][var].str.findall(r\"\\b0[1-9](?:[\\s.-]?[0-9]){8}\\b\")\n",
    "    df.loc[telephone.apply(len)>0,var+'_telephone'] = telephone[telephone.apply(len)>0].apply(lambda x:' '.join([re.sub(r'[^0-9]', '', i) for i in x]))\n",
    "    \n",
    "    siren = df[~df[var].isna()][var].str.findall(r\"\\b(?:[\\s.-]?[0-9]){9}\\b\")\n",
    "    df.loc[siren.apply(len)>0,var+'_siren'] = siren[siren.apply(len)>0].apply(lambda x:' '.join([re.sub(r'[^0-9]', '', i) for i in x]))\n",
    "\n",
    "    siret = df[~df[var].isna()][var].str.findall(r\"\\b(?:[\\s.-]?[0-9]){14}\\b\")\n",
    "    df.loc[siret.apply(len)>0,var+'_siret'] = siret[siret.apply(len)>0].apply(lambda x:' '.join([re.sub(r'[^0-9]', '', i) for i in x]))\n",
    "\n",
    "    #pacage = df[~df[var].isna()][var].str.findall(r\"\\b066\\d{6}\\b\")\n",
    "    #df.loc[pacage.apply(len)>0,var+'_pacage'] = pacage[pacage.apply(len)>0].apply(lambda x:' '.join([re.sub(r'[^0-9]', '', i) for i in x]))\n",
    "    \n",
    "    temp.append(df.drop(var, axis=1))\n",
    "    \n",
    "df_commentaires = reduce(lambda left, right: pd.merge(left , right, on = [\"NOM_DOSSIER\"], how = \"outer\"), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "118c7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commentaires.dropna(how='all').to_csv('IDENTIFICATION_parser.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
